{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate_scores.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbE7R9sHRzYf",
        "outputId": "007e5577-d436-4763-a321-44ac173077d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benjaminrike1/social_score_csr_reports.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSAXYvYZR40T",
        "outputId": "818c1103-26dd-4b8e-a145-7d3fa4230239"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'social_score_csr_reports'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 259 (delta 14), reused 43 (delta 13), pack-reused 215\u001b[K\n",
            "Receiving objects: 100% (259/259), 786.58 MiB | 21.22 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "Checking out files: 100% (79/79), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pickle5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07e4scYLiYGc",
        "outputId": "15ed06c0-3f5c-46e5-e5c2-5d1a6e2f94d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyNBJatOTVlU",
        "outputId": "9e36a360-70c9-4e32-ae45-2db88746ebed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Collecting tensorflow<2.10,>=2.9.0\n",
            "  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 3.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.46.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.0.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (14.0.1)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.17.3)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.21.6)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 26.9 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 32.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.25.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.0 tensorflow-2.9.0 tensorflow-estimator-2.9.0 tensorflow-text-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q tf-models-official==2.7.0"
      ],
      "metadata": {
        "id": "W4xyksIVTbk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad32abc1-08d8-4842-d9d0-00517d681ebb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 56 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 36.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 38.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 37.1 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import pandas as pd\n",
        "import pickle5 as pickle"
      ],
      "metadata": {
        "id": "6GYdjrSCSIX_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'social_score_csr_reports/models/models/'\n",
        "reloaded_model = tf.saved_model.load(model_path)\n"
      ],
      "metadata": {
        "id": "s7XhOk1iSBOw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_my_examples(inputs, results):\n",
        "  print(\"Probabilities is on the format: neutral, positive, negative\")\n",
        "  result_for_printing = \\\n",
        "    [f'input: {inputs[i]:<30} : \\n Probability: Signal: {results[i][0]:.2f}    Noise: {results[i][1]:.2f}'\n",
        "                         for i in range(len(inputs))]\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()\n",
        "\n",
        "\n",
        "examples = [\n",
        "    'In 2020, we continued to provide a framework of policies, standards, and implementation expectations to guide our supplier business relationships',\n",
        "    'In 2020, we conducted risk assessments to help us identify and prioritize the most critical issue areas and suppliers. ',\n",
        "    'We invest in charitable and community causes in all of our markets and our people regularly take part in volunteering activities to support social initiatives in our communities.',\n",
        "    'As signatories of the Valuable 500 pledge, we are committed to putting disability on the business leadership agenda',\n",
        "    'Our diversity was reduced this year',\n",
        "    'Football is a sport',\n",
        "    'In 2020, 35.6% of leadership positions were held by women, up from 35.5% in 2019. ',\n",
        "    'Zero fatalities occurred during the year',\n",
        "    'The launch of our cultural change CARE programme, which will embed ‘the seven health and safety habits’ within our organisation, was another success and', #positive\n",
        "    '22% of our senior leadership team members are women', #negative?\n",
        "    'Our Health and Safety Management System', #neutral\n",
        "    'During the first quarter of 2021, we saw a spike in health and safety incidents',\n",
        "    'Even though one uses generally the same letter “M” for both martingales and Markov process, these are a priori completely different processes!',\n",
        "    'Not every process is either a sub- or a supermartingale',\n",
        "    'This repository is for the exercises, homework and project. The course syllabus can be found here.',\n",
        "    'Jeg heter Benjamin og skriver på norsk',\n",
        "    'To establish the communication between the robot and the cloud via Wi-Fi, you need to find the IP address, as shown in Figure 3.',\n",
        "    'We have drastically reduced our CO2 emission this year as we prepare to meet the latest regulatory demands.'\n",
        "]\n",
        "reloaded_results = tf.nn.softmax(reloaded_model(tf.constant(examples)))\n",
        "\n",
        "print('Results from the model:')\n",
        "print_my_examples(examples, reloaded_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmBWFLa9SG6I",
        "outputId": "9e54ffa9-8f2b-4af3-c76d-a0a450757618"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from the model:\n",
            "Probabilities is on the format: neutral, positive, negative\n",
            "input: In 2020, we continued to provide a framework of policies, standards, and implementation expectations to guide our supplier business relationships : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: In 2020, we conducted risk assessments to help us identify and prioritize the most critical issue areas and suppliers.  : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: We invest in charitable and community causes in all of our markets and our people regularly take part in volunteering activities to support social initiatives in our communities. : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: As signatories of the Valuable 500 pledge, we are committed to putting disability on the business leadership agenda : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Our diversity was reduced this year : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Football is a sport            : \n",
            " Probability: Signal: 0.01    Noise: 0.99\n",
            "input: In 2020, 35.6% of leadership positions were held by women, up from 35.5% in 2019.  : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Zero fatalities occurred during the year : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: The launch of our cultural change CARE programme, which will embed ‘the seven health and safety habits’ within our organisation, was another success and : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: 22% of our senior leadership team members are women : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Our Health and Safety Management System : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: During the first quarter of 2021, we saw a spike in health and safety incidents : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Even though one uses generally the same letter “M” for both martingales and Markov process, these are a priori completely different processes! : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "input: Not every process is either a sub- or a supermartingale : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "input: This repository is for the exercises, homework and project. The course syllabus can be found here. : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Jeg heter Benjamin og skriver på norsk : \n",
            " Probability: Signal: 0.43    Noise: 0.57\n",
            "input: To establish the communication between the robot and the cloud via Wi-Fi, you need to find the IP address, as shown in Figure 3. : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "input: We have drastically reduced our CO2 emission this year as we prepare to meet the latest regulatory demands. : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'social_score_csr_reports/reports_df.pickle'\n",
        "with open(filename, 'rb') as fh:\n",
        "  data = pickle.load(fh)\n",
        "\n",
        "data.drop(labels=['text'], inplace=True, axis=1)\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mCFWci55Tkl1",
        "outputId": "13dc96c9-ae46-4e02-d53d-7ce656a99c4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Company                                          sentences\n",
              "0   ABNAMRO  [ABN AMRO’s business,  strategy, performance a...\n",
              "1  AgroFair  [SUSTAINABILITY REPORT 2020, - 03 -CONTENT IND...\n",
              "2    Amazon  [All In: Staying the Course  on Our Commitment...\n",
              "3       asr  [Ditisdetijd, vandoen., Annual Report2020, ASR...\n",
              "4       bam  [Integrated Report 2020, Royal BAM Group nv, R..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc8a0f6d-a9b6-4973-9439-f994c166aae8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABNAMRO</td>\n",
              "      <td>[ABN AMRO’s business,  strategy, performance a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AgroFair</td>\n",
              "      <td>[SUSTAINABILITY REPORT 2020, - 03 -CONTENT IND...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazon</td>\n",
              "      <td>[All In: Staying the Course  on Our Commitment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asr</td>\n",
              "      <td>[Ditisdetijd, vandoen., Annual Report2020, ASR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bam</td>\n",
              "      <td>[Integrated Report 2020, Royal BAM Group nv, R...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc8a0f6d-a9b6-4973-9439-f994c166aae8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc8a0f6d-a9b6-4973-9439-f994c166aae8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc8a0f6d-a9b6-4973-9439-f994c166aae8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "scores = [] #saving the individual company scores\n",
        "\n",
        "# iterating over every company\n",
        "for element in data['Company'].values:\n",
        "  # extracting all sentences from the report\n",
        "  features = data[data['Company']==element]['sentences'].values[0] \n",
        "  total_sentences = len(features)\n",
        "\n",
        "  # variables for saving signal\n",
        "  signal = 0\n",
        "\n",
        "  # hitting the model with sentences in chunks to avoid RAM overload\n",
        "  for chunk in chunks(features, 128):\n",
        "      # calculating softmax for every sentence\n",
        "      results = tf.nn.softmax(reloaded_model(tf.constant(chunk)))\n",
        "      # argmax to extract label\n",
        "      argmax = tf.math.argmax(results, axis = 1).numpy()\n",
        "\n",
        "      #counting pos sentences\n",
        "      signal += np.count_nonzero(argmax==0)\n",
        "  # assigning total scores realtive to number of sentences\n",
        "  score = (signal)/total_sentences\n",
        "  scores.append(score)"
      ],
      "metadata": {
        "id": "OTndwYWdky3v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['scores'] = scores"
      ],
      "metadata": {
        "id": "fCsHZAL6lhcw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['scores'] = data['scores'].apply(lambda x: 1-x)"
      ],
      "metadata": {
        "id": "MI-g5cB_hhuy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['Company', 'scores']].to_csv('drive/MyDrive/ml/social_scores.csv')"
      ],
      "metadata": {
        "id": "M_XjN8ctplkA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,element in enumerate(data['scores']):\n",
        "  print(\"%s: %.3f\"%(data['Company'].values[i],element))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr5dETGNsMj2",
        "outputId": "f4e76cb2-9b81-499d-e7fc-beda196c6956"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABNAMRO: 0.254\n",
            "AgroFair: 0.290\n",
            "Amazon: 0.322\n",
            "asr: 0.280\n",
            "bam: 0.381\n",
            "CocaCola: 0.318\n",
            "Dataflex: 0.321\n",
            "DS-Smith: 0.293\n",
            "Essity: 0.364\n",
            "Facebook: 0.339\n",
            "Forbo: 0.300\n",
            "Google: 0.189\n",
            "GrandVision: 0.467\n",
            "Grolsch: 0.248\n",
            "heineken: 0.307\n",
            "HEMA: 0.401\n",
            "Henkel: 0.337\n",
            "HP: 0.332\n",
            "ING: 0.332\n",
            "Intel: 0.306\n",
            "KPN: 0.297\n",
            "Microsoft: 0.165\n",
            "NNgroup: 0.319\n",
            "Optigroup: 0.284\n",
            "PepsiCo: 0.326\n",
            "Philips: 0.367\n",
            "ProcterandGamble: 0.462\n",
            "Renewi: 0.274\n",
            "Rockwool: 0.283\n",
            "Royal-Avebe: 0.368\n",
            "Shell: 0.189\n",
            "tarkett: 0.390\n",
            "Tesla: 0.248\n",
            "Trivium: 0.233\n",
            "VanLanschot: 0.413\n"
          ]
        }
      ]
    }
  ]
}