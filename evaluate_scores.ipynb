{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate_scores.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbE7R9sHRzYf",
        "outputId": "a4ca4c87-d895-4b64-a2e3-ac843f87656b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benjaminrike1/social_score_csr_reports.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSAXYvYZR40T",
        "outputId": "77d516f5-9cce-407e-961e-57e1c83b4c4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'social_score_csr_reports'...\n",
            "remote: Enumerating objects: 419, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 419 (delta 0), reused 1 (delta 0), pack-reused 415\u001b[K\n",
            "Receiving objects: 100% (419/419), 1.69 GiB | 17.15 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Checking out files: 100% (156/156), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pickle5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07e4scYLiYGc",
        "outputId": "dc2bad3d-b80f-4c80-d214-286d66eafcef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 34.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyNBJatOTVlU",
        "outputId": "a0c92325-3aee-4f65-c7df-e69fbb5ee608"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Collecting tensorflow<2.10,>=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.46.1)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 57.4 MB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.21.6)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (14.0.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.26.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.17.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.0 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-text-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q tf-models-official==2.7.0"
      ],
      "metadata": {
        "id": "W4xyksIVTbk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d822948-9d51-46e3-88f9-013dcdf278da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 30.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 92 kB 11.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 9.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 26.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 77.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 17.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 6.7 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import pandas as pd\n",
        "import pickle5 as pickle"
      ],
      "metadata": {
        "id": "6GYdjrSCSIX_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'social_score_csr_reports/models/no_aug/'\n",
        "reloaded_model = tf.saved_model.load(model_path)\n"
      ],
      "metadata": {
        "id": "s7XhOk1iSBOw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_my_examples(inputs, results):\n",
        "  print(\"Probabilities is on the format: neutral, positive, negative\")\n",
        "  result_for_printing = \\\n",
        "    [f'input: {inputs[i]:<30} : \\n Probability: Signal: {results[i][0]:.2f}    Noise: {results[i][1]:.2f}'\n",
        "                         for i in range(len(inputs))]\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()\n",
        "\n",
        "\n",
        "examples = [\n",
        "    'In 2020, we continued to provide a framework of policies, standards, and implementation expectations to guide our supplier business relationships',\n",
        "    'In 2020, we conducted risk assessments to help us identify and prioritize the most critical issue areas and suppliers. ',\n",
        "    'We invest in charitable and community causes in all of our markets and our people regularly take part in volunteering activities to support social initiatives in our communities.',\n",
        "    'As signatories of the Valuable 500 pledge, we are committed to putting disability on the business leadership agenda',\n",
        "    'Our diversity was reduced this year',\n",
        "    'Football is a sport',\n",
        "    'In 2020, 35.6% of leadership positions were held by women, up from 35.5% in 2019. ',\n",
        "    'Zero fatalities occurred during the year',\n",
        "    'The launch of our cultural change CARE programme, which will embed ‘the seven health and safety habits’ within our organisation, was another success and', #positive\n",
        "    '22% of our senior leadership team members are women', #negative?\n",
        "    'Our Health and Safety Management System', #neutral\n",
        "    'During the first quarter of 2021, we saw a spike in health and safety incidents',\n",
        "    'Even though one uses generally the same letter “M” for both martingales and Markov process, these are a priori completely different processes!',\n",
        "    'Not every process is either a sub- or a supermartingale',\n",
        "    'This repository is for the exercises, homework and project. The course syllabus can be found here.',\n",
        "    'Jeg heter Benjamin og skriver på norsk',\n",
        "    'To establish the communication between the robot and the cloud via Wi-Fi, you need to find the IP address, as shown in Figure 3.',\n",
        "    'We have drastically reduced our CO2 emission this year as we prepare to meet the latest regulatory demands.'\n",
        "]\n",
        "reloaded_results = tf.nn.softmax(reloaded_model(tf.constant(examples)))\n",
        "\n",
        "print('Results from the model:')\n",
        "print_my_examples(examples, reloaded_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmBWFLa9SG6I",
        "outputId": "e7f78877-38a6-4df7-de81-3c33c11991e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from the model:\n",
            "Probabilities is on the format: neutral, positive, negative\n",
            "input: In 2020, we continued to provide a framework of policies, standards, and implementation expectations to guide our supplier business relationships : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: In 2020, we conducted risk assessments to help us identify and prioritize the most critical issue areas and suppliers.  : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: We invest in charitable and community causes in all of our markets and our people regularly take part in volunteering activities to support social initiatives in our communities. : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: As signatories of the Valuable 500 pledge, we are committed to putting disability on the business leadership agenda : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Our diversity was reduced this year : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Football is a sport            : \n",
            " Probability: Signal: 0.01    Noise: 0.99\n",
            "input: In 2020, 35.6% of leadership positions were held by women, up from 35.5% in 2019.  : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Zero fatalities occurred during the year : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: The launch of our cultural change CARE programme, which will embed ‘the seven health and safety habits’ within our organisation, was another success and : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: 22% of our senior leadership team members are women : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Our Health and Safety Management System : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: During the first quarter of 2021, we saw a spike in health and safety incidents : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Even though one uses generally the same letter “M” for both martingales and Markov process, these are a priori completely different processes! : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "input: Not every process is either a sub- or a supermartingale : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "input: This repository is for the exercises, homework and project. The course syllabus can be found here. : \n",
            " Probability: Signal: 1.00    Noise: 0.00\n",
            "input: Jeg heter Benjamin og skriver på norsk : \n",
            " Probability: Signal: 0.43    Noise: 0.57\n",
            "input: To establish the communication between the robot and the cloud via Wi-Fi, you need to find the IP address, as shown in Figure 3. : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "input: We have drastically reduced our CO2 emission this year as we prepare to meet the latest regulatory demands. : \n",
            " Probability: Signal: 0.00    Noise: 1.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'social_score_csr_reports/all_reports_df.pickle'\n",
        "with open(filename, 'rb') as fh:\n",
        "  data = pickle.load(fh)\n",
        "data.reset_index(inplace=True)\n",
        "data.drop(labels=['Company'], inplace=True, axis=1)\n",
        "data.rename({'index':'Company'}, axis=1, inplace=True)\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "mCFWci55Tkl1",
        "outputId": "0bf8822e-80fe-477c-ca41-6c7aba68df94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Company                                     sentences_2016  \\\n",
              "0   ABNAMRO  [ABN AMRO Group N.V., Integrated   Annual Repo...   \n",
              "1    Amazon  [“Jeff, what does Day 2 look like?”, That’s a ...   \n",
              "2       asr  [2016, Annual Report, a.s.r., Archimedeslaan 1...   \n",
              "3       bam  [Integrated ReportIntegrated Report 2015  , Ro...   \n",
              "4  CocaCola  [Coca‑Cola European Partners plcAnnual Report ...   \n",
              "\n",
              "                                      sentences_2017  \\\n",
              "0  [ABN AMRO Bank N.V., ABN AMRO Group N.V., Inte...   \n",
              "1  [2, 0, 1, 7, A N N , U A , LR E P O R T, To ou...   \n",
              "2  [2017, Annual Report  , ASR Nederland N.V., Ar...   \n",
              "3  [Colophon, Royal BAM Group nv, Runnenburg 9, 3...   \n",
              "4  [DELIGHTING  CUSTOMERS  AND CONSUMERS, Coca‑Co...   \n",
              "\n",
              "                                      sentences_2018  \\\n",
              "0  [Banking  for better,  for generations  to com...   \n",
              "1  [2, 0, 1, 8, A N N , U A , LR E P O R T, To ou...   \n",
              "2  [Annual Report2018, ASR Nederland N.V., Archim...   \n",
              "3  [Royal BAM Group nv, Runnenburg 9, 3981 , AZ B...   \n",
              "4  [GREAT BEVERAGES , GREAT SERVICE , GREAT PEOPL...   \n",
              "\n",
              "                                      sentences_2019  \\\n",
              "0  [Accelerating the sustainability , shift, ABN ...   \n",
              "1  [ Sustainability:  , Thinking Big September 20...   \n",
              "2  [Annual Report2019, ASR Nederland N.V., Archim...   \n",
              "3  [Integrated Report 2019, BAM plants 150,000 tr...   \n",
              "4  [GREAT PEOPLEGREAT SERVICE, GREAT BEVERAGES , ...   \n",
              "\n",
              "                                      sentences_2020  \n",
              "0  [ABN AMRO’s business,  strategy, performance a...  \n",
              "1  [All In: Staying the Course  on Our Commitment...  \n",
              "2  [Ditisdetijd, vandoen., Annual Report2020, ASR...  \n",
              "3  [Integrated Report 2020, Royal BAM Group nv, R...  \n",
              "4  [GREAT PEOPLEGREAT SERVICE, GREAT BEVERAGES, 2...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d2b4ab8-9594-4040-ae79-bca425a8e89a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>sentences_2016</th>\n",
              "      <th>sentences_2017</th>\n",
              "      <th>sentences_2018</th>\n",
              "      <th>sentences_2019</th>\n",
              "      <th>sentences_2020</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABNAMRO</td>\n",
              "      <td>[ABN AMRO Group N.V., Integrated   Annual Repo...</td>\n",
              "      <td>[ABN AMRO Bank N.V., ABN AMRO Group N.V., Inte...</td>\n",
              "      <td>[Banking  for better,  for generations  to com...</td>\n",
              "      <td>[Accelerating the sustainability , shift, ABN ...</td>\n",
              "      <td>[ABN AMRO’s business,  strategy, performance a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Amazon</td>\n",
              "      <td>[“Jeff, what does Day 2 look like?”, That’s a ...</td>\n",
              "      <td>[2, 0, 1, 7, A N N , U A , LR E P O R T, To ou...</td>\n",
              "      <td>[2, 0, 1, 8, A N N , U A , LR E P O R T, To ou...</td>\n",
              "      <td>[ Sustainability:  , Thinking Big September 20...</td>\n",
              "      <td>[All In: Staying the Course  on Our Commitment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>asr</td>\n",
              "      <td>[2016, Annual Report, a.s.r., Archimedeslaan 1...</td>\n",
              "      <td>[2017, Annual Report  , ASR Nederland N.V., Ar...</td>\n",
              "      <td>[Annual Report2018, ASR Nederland N.V., Archim...</td>\n",
              "      <td>[Annual Report2019, ASR Nederland N.V., Archim...</td>\n",
              "      <td>[Ditisdetijd, vandoen., Annual Report2020, ASR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bam</td>\n",
              "      <td>[Integrated ReportIntegrated Report 2015  , Ro...</td>\n",
              "      <td>[Colophon, Royal BAM Group nv, Runnenburg 9, 3...</td>\n",
              "      <td>[Royal BAM Group nv, Runnenburg 9, 3981 , AZ B...</td>\n",
              "      <td>[Integrated Report 2019, BAM plants 150,000 tr...</td>\n",
              "      <td>[Integrated Report 2020, Royal BAM Group nv, R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CocaCola</td>\n",
              "      <td>[Coca‑Cola European Partners plcAnnual Report ...</td>\n",
              "      <td>[DELIGHTING  CUSTOMERS  AND CONSUMERS, Coca‑Co...</td>\n",
              "      <td>[GREAT BEVERAGES , GREAT SERVICE , GREAT PEOPL...</td>\n",
              "      <td>[GREAT PEOPLEGREAT SERVICE, GREAT BEVERAGES , ...</td>\n",
              "      <td>[GREAT PEOPLEGREAT SERVICE, GREAT BEVERAGES, 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d2b4ab8-9594-4040-ae79-bca425a8e89a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d2b4ab8-9594-4040-ae79-bca425a8e89a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d2b4ab8-9594-4040-ae79-bca425a8e89a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns.values[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgpeqdVnGDzk",
        "outputId": "de001ef7-9bd7-4918-a1b9-11d4d99b4b34"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sentences_2016', 'sentences_2017', 'sentences_2018',\n",
              "       'sentences_2019', 'sentences_2020'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "scores = [] #saving the individual company scores\n",
        "columns = data.columns\n",
        "\n",
        "# iterating over every company\n",
        "for element in data['Company'].values:\n",
        "  comp_scores = []\n",
        "  for report in data.columns.values[1:]:\n",
        "    # extracting all sentences from the report\n",
        "    features = data[data['Company']==element][report].values[0] \n",
        "    total_sentences = len(features)\n",
        "\n",
        "    # variables for saving signal\n",
        "    signal = 0\n",
        "\n",
        "    # hitting the model with sentences in chunks to avoid RAM overload\n",
        "    for batch in chunks(features, 128):\n",
        "        # calculating softmax for every sentence\n",
        "        results = tf.nn.softmax(reloaded_model(tf.constant(batch)))\n",
        "        # argmax to extract label\n",
        "        argmax = tf.math.argmax(results, axis = 1).numpy()\n",
        "\n",
        "        #counting pos sentences\n",
        "        signal += np.count_nonzero(argmax==0)\n",
        "    # assigning total scores realtive to number of sentences\n",
        "    comp_scores.append(signal)\n",
        "  scores.append(comp_scores)"
      ],
      "metadata": {
        "id": "OTndwYWdky3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = np.asarray(scores)\n",
        "scores = scores.T\n",
        "\n",
        "func = lambda x: 1-x\n",
        "\n",
        "data['scores_2017'] = [func(x) for x in scores[0]]\n",
        "data['scores_2018'] = [func(x) for x in scores[1]]\n",
        "data['scores_2019'] = [func(x) for x in scores[2]]\n",
        "data['scores_2020'] = [func(x) for x in scores[3]]\n",
        "data['scores_2021'] = [func(x) for x in scores[4]]"
      ],
      "metadata": {
        "id": "dGSXShQNG7Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['Company', 'scores_2017','scores_2018','scores_2019','scores_2020','scores_2021']].to_csv('drive/MyDrive/ml/social_scores.csv')"
      ],
      "metadata": {
        "id": "M_XjN8ctplkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,element in enumerate(data['scores_2021']):\n",
        "  print(\"%s: %.3f\"%(data['Company'].values[i],element))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr5dETGNsMj2",
        "outputId": "f4e76cb2-9b81-499d-e7fc-beda196c6956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABNAMRO: 0.254\n",
            "AgroFair: 0.290\n",
            "Amazon: 0.322\n",
            "asr: 0.280\n",
            "bam: 0.381\n",
            "CocaCola: 0.318\n",
            "Dataflex: 0.321\n",
            "DS-Smith: 0.293\n",
            "Essity: 0.364\n",
            "Facebook: 0.339\n",
            "Forbo: 0.300\n",
            "Google: 0.189\n",
            "GrandVision: 0.467\n",
            "Grolsch: 0.248\n",
            "heineken: 0.307\n",
            "HEMA: 0.401\n",
            "Henkel: 0.337\n",
            "HP: 0.332\n",
            "ING: 0.332\n",
            "Intel: 0.306\n",
            "KPN: 0.297\n",
            "Microsoft: 0.165\n",
            "NNgroup: 0.319\n",
            "Optigroup: 0.284\n",
            "PepsiCo: 0.326\n",
            "Philips: 0.367\n",
            "ProcterandGamble: 0.462\n",
            "Renewi: 0.274\n",
            "Rockwool: 0.283\n",
            "Royal-Avebe: 0.368\n",
            "Shell: 0.189\n",
            "tarkett: 0.390\n",
            "Tesla: 0.248\n",
            "Trivium: 0.233\n",
            "VanLanschot: 0.413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RLY9zoeyH2cJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}